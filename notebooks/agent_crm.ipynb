{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f4bbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from openai import OpenAI\n",
    "\n",
    "# Digite sua chave\n",
    "openai_key = getpass.getpass(\"Digite sua chave OpenAI: \")\n",
    "\n",
    "# Define a variável de ambiente\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7b1f00f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de chunks criados: 82\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "with open('../data/processed/crm_conversas_anonimizadas.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "text = text[:100_000]  # só os primeiros 100 mil caracteres (~15 mil palavras)\n",
    "\n",
    "docs = [Document(page_content=text)]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,        # menor chunk para menos tokens\n",
    "    chunk_overlap=200,      # overlap menor para menos repetição\n",
    "    add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Total de chunks criados: {len(all_splits)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1e376e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "batch_size = 10  # bem leve\n",
    "vectorstores = []\n",
    "\n",
    "for i in range(0, len(all_splits), batch_size):\n",
    "    batch = all_splits[i:i + batch_size]\n",
    "    store = FAISS.from_documents(batch, embeddings)\n",
    "    vectorstores.append(store)\n",
    "\n",
    "# Juntar todos os vetores se necessário\n",
    "vectorstore = vectorstores[0]\n",
    "for store in vectorstores[1:]:\n",
    "    vectorstore.merge_from(store)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e57ec84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore.save_local(\"meus_embeddings/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71e4a913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"Qual o maior motivo de insatisfação?\")\n",
    "\n",
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edca4bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<br />08:42\n",
      "<br />\n",
      "<br />Resposta\n",
      "<br />\n",
      "<br />E registra minha reclamação dessa atualização da biometria\n",
      "<br />\n",
      "<br />Você pode abrir um CRM informando a sua insatisfação com a biometria.\n",
      "<br />\n",
      "<br />Você vai no Portal, clica em ?Outros Serviços? ou em qualquer opção que abra o S4E. Aí vai aparecer uma barra de ferramentas, na qual você escolherá a opção ?CRM?(Ícone de balão colorido). Depois você clica no sinal de + (verde) para abrir o chamado. Lá você coloca a solicitação e descreve a situação.\n",
      "<br />\n",
      "<br />\n",
      "<br />Resposta\n",
      "<br />\n",
      "<br />Não recebi o kit pq não entrou !!\n",
      "<br />\n",
      "<br />Como lhe informei anteriormente. O procedimento só pode realizado após a baixa do procedimento em sistema. Caso você esteja com dificuldade na validação da biometria você precisa contatar a central do dentista de imediato para que possamos lhe auxiliar\n",
      "<br />\n",
      "<br />Posso te ajudar com mais alguma informação?\n",
      "<br />\n",
      "<br />08:43\n",
      "<br />Espero ter ajudado!\n",
      "<br />\n",
      "<br />Agora vou te transferir para a pesquisa de satisfação. Essa avaliação é de como foi sua experiência comigo neste atendimento, com resposta de 4 a 5. Então, se você gostou, as notas 4 e 5 vão demonstrar essa sua satisfação. Te agradeço por participar. Tenha um excelente dia.??\n",
      "<br />\n",
      "<br />08:46\n",
      "<br />\n",
      "<br />\n",
      "<br />\n",
      "<br />\n",
      "<br />\n",
      "<br />\n",
      "<br />\n",
      "<br />\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "120a7878",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_template = \"\"\"Você é um assistente para tarefas de perguntas e respostas. Use os seguintes trechos de contexto recuperados para responder à pergunta. Se você não souber a resposta, apenas diga que não sabe. Use no máximo duas frases e mantenha a resposta concisa e fale apenas o necessário.\n",
    "\n",
    "Pergunta: {question}\n",
    "\n",
    "Contexto: {context}\n",
    "\n",
    "Resposta:\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(system_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4cfc7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19b12ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt_template\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb9e019a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os clientes estão insatisfeitos principalmente com o atendimento, dificuldades na biometria e falta de informações sobre procedimentos e pagamentos. Além disso, houve reclamações sobre o agendamento de consultas e o não cumprimento de horários."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"Qual a insatisfação dos clientes?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
